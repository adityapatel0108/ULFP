{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Machine Unlearning Experiments\n",
        "\n",
        "This notebook demonstrates unlearning operations on linearized models:\n",
        "- Unlearning specific identities\n",
        "- Comparing different unlearning methods\n",
        "- Evaluating unlearning effectiveness\n",
        "\n",
        "## Objectives\n",
        "1. Perform unlearning operations\n",
        "2. Compare unlearning methods\n",
        "3. Verify unlearning effectiveness\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import yaml\n",
        "from tqdm import tqdm\n",
        "\n",
        "from utils.model_loader import load_model_from_config\n",
        "from linearizer.linearizer import Linearizer\n",
        "from unlearning.unlearning import UnlearningEngine\n",
        "from data.dataloader import get_ms1mv2_dataloader\n",
        "\n",
        "# Load configuration\n",
        "with open('../config.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Linearized Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model and create linearizer (assuming already trained)\n",
        "# In practice, you would load a saved linearizer checkpoint\n",
        "model = load_model_from_config(config)\n",
        "model = model.to(device)\n",
        "\n",
        "linearizer_config = config['linearizer']\n",
        "linearizer = Linearizer(\n",
        "    model=model,\n",
        "    embedding_size=config['model'].get('embedding_size', 512),\n",
        "    num_blocks=linearizer_config.get('num_blocks', 4),\n",
        "    hidden_dim=linearizer_config.get('hidden_dim', 1024)\n",
        ")\n",
        "linearizer = linearizer.to(device)\n",
        "\n",
        "print(\"Linearizer loaded\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Select Identities to Unlearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select identities to unlearn\n",
        "# In practice, you would select specific identity IDs\n",
        "identity_ids_to_unlearn = config['unlearning'].get('target_identities', [0, 1, 2, 3, 4])\n",
        "\n",
        "# If empty, select some random identities from dataset\n",
        "if len(identity_ids_to_unlearn) == 0:\n",
        "    ms1mv2_path = config['data']['ms1mv2']['path']\n",
        "    from data.dataset import MS1MV2Dataset\n",
        "    dataset = MS1MV2Dataset(ms1mv2_path, is_training=False)\n",
        "    unique_identities = list(set([label.item() for _, label in dataset]))\n",
        "    identity_ids_to_unlearn = unique_identities[:5]  # Select first 5\n",
        "\n",
        "print(f\"Identities to unlearn: {identity_ids_to_unlearn}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Perform Unlearning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create unlearning engine\n",
        "unlearning_method = config['unlearning'].get('method', 'orthogonal_projection')\n",
        "unlearning_engine = UnlearningEngine(linearizer, method=unlearning_method)\n",
        "\n",
        "# Load data for unlearning\n",
        "ms1mv2_path = config['data']['ms1mv2']['path']\n",
        "dataloader = get_ms1mv2_dataloader(ms1mv2_path, batch_size=64, is_training=True)\n",
        "\n",
        "# Perform unlearning\n",
        "print(f\"Unlearning using method: {unlearning_method}\")\n",
        "print(\"This may take a while...\")\n",
        "\n",
        "updated_operator = unlearning_engine.unlearn(\n",
        "    dataloader,\n",
        "    identity_ids_to_unlearn,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(\"Unlearning completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Verify Unlearning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify unlearning effectiveness\n",
        "from unlearning.evaluation import compute_unlearning_metrics\n",
        "\n",
        "# Get retain identities (all except unlearned)\n",
        "ms1mv2_path = config['data']['ms1mv2']['path']\n",
        "from data.dataset import MS1MV2Dataset\n",
        "dataset = MS1MV2Dataset(ms1mv2_path, is_training=False)\n",
        "all_identities = list(set([label.item() for _, label in dataset]))\n",
        "identity_ids_to_retain = [id for id in all_identities if id not in identity_ids_to_unlearn]\n",
        "\n",
        "# Evaluate\n",
        "test_dataloader = get_ms1mv2_dataloader(ms1mv2_path, batch_size=64, is_training=False)\n",
        "\n",
        "metrics = compute_unlearning_metrics(\n",
        "    original_model=model,\n",
        "    unlearned_model=linearizer,\n",
        "    dataloader=test_dataloader,\n",
        "    identity_ids_to_forget=identity_ids_to_unlearn,\n",
        "    identity_ids_to_retain=identity_ids_to_retain[:100],  # Limit for speed\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(\"\\nUnlearning Metrics:\")\n",
        "for key, value in metrics.items():\n",
        "    print(f\"{key}: {value:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
