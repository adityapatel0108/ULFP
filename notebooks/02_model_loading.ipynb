{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Loading and Testing\n",
        "\n",
        "This notebook demonstrates how to load pretrained face recognition models:\n",
        "- InsightFace models (buffalo_l)\n",
        "- iResNet models\n",
        "\n",
        "## Objectives\n",
        "1. Load pretrained models\n",
        "2. Test model inference\n",
        "3. Extract face embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import yaml\n",
        "\n",
        "from utils.model_loader import load_insightface_model, load_model_from_config\n",
        "from data.dataset import MS1MV2Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Load configuration\n",
        "with open('../config.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load InsightFace Model (buffalo_l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load InsightFace model\n",
        "try:\n",
        "    if config['model'].get('use_insightface', False):\n",
        "        model_name = config['model'].get('insightface_model', 'buffalo_l')\n",
        "        print(f\"Loading InsightFace model: {model_name}\")\n",
        "        \n",
        "        # Load using InsightFace\n",
        "        app = load_insightface_model(model_name)\n",
        "        print(\"InsightFace model loaded successfully\")\n",
        "        \n",
        "        # Note: InsightFace models work differently - they use FaceAnalysis app\n",
        "        # For our purposes, we'll create a wrapper or use iResNet models\n",
        "        print(\"\\nNote: For linearization, we recommend using iResNet models\")\n",
        "        print(\"Set use_insightface: false in config.yaml to use iResNet\")\n",
        "    else:\n",
        "        print(\"InsightFace not configured. Using iResNet models instead.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading InsightFace model: {e}\")\n",
        "    print(\"Falling back to iResNet models\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load iResNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model from config\n",
        "try:\n",
        "    model = load_model_from_config(config)\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    print(\"Model loaded successfully\")\n",
        "    print(f\"Model type: {type(model)}\")\n",
        "    \n",
        "    # Test with dummy input\n",
        "    dummy_input = torch.randn(1, 3, 112, 112).to(device)\n",
        "    with torch.no_grad():\n",
        "        embeddings = model.extract_features(dummy_input)\n",
        "        print(f\"Embedding shape: {embeddings.shape}\")\n",
        "        print(f\"Embedding norm: {embeddings.norm(dim=1).item():.4f}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    print(\"Please check model configuration in config.yaml\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Test on Sample Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load sample images from dataset\n",
        "try:\n",
        "    ms1mv2_path = config['data']['ms1mv2']['path']\n",
        "    dataset = MS1MV2Dataset(ms1mv2_path, is_training=False)\n",
        "    dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "    \n",
        "    # Get a batch\n",
        "    images, labels = next(iter(dataloader))\n",
        "    images = images.to(device)\n",
        "    \n",
        "    # Extract embeddings\n",
        "    with torch.no_grad():\n",
        "        embeddings = model.extract_features(images)\n",
        "    \n",
        "    # Visualize\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "    for i in range(4):\n",
        "        axes[0, i].imshow(images[i].cpu().permute(1, 2, 0) * 0.5 + 0.5)\n",
        "        axes[0, i].set_title(f\"Identity: {labels[i].item()}\")\n",
        "        axes[0, i].axis('off')\n",
        "        \n",
        "        # Show embedding (first 10 dimensions)\n",
        "        emb_plot = embeddings[i].cpu().numpy()[:10]\n",
        "        axes[1, i].bar(range(10), emb_plot)\n",
        "        axes[1, i].set_title(f\"Embedding (first 10 dims)\")\n",
        "        axes[1, i].set_ylim(-1, 1)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Compute similarity between images\n",
        "    embeddings_norm = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n",
        "    similarity_matrix = embeddings_norm @ embeddings_norm.T\n",
        "    print(\"\\nSimilarity matrix:\")\n",
        "    print(similarity_matrix.cpu().numpy())\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Error testing model: {e}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
