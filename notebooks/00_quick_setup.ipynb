{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Quick Setup and Verification\n",
        "\n",
        "Run this notebook first to verify your setup is correct before training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add project root to path\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Get current directory (should be notebooks/)\n",
        "current_dir = os.getcwd()\n",
        "if current_dir.endswith('notebooks'):\n",
        "    project_root = os.path.dirname(current_dir)\n",
        "else:\n",
        "    project_root = current_dir\n",
        "\n",
        "sys.path.insert(0, os.path.join(project_root, 'src'))\n",
        "sys.path.insert(0, project_root)\n",
        "\n",
        "print(f\"Project root: {project_root}\")\n",
        "print(f\"Python path includes: {sys.path[:3]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Check Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import importlib\n",
        "\n",
        "required = {\n",
        "    'torch': 'PyTorch',\n",
        "    'torchvision': 'TorchVision',\n",
        "    'insightface': 'InsightFace',\n",
        "    'numpy': 'NumPy',\n",
        "    'yaml': 'PyYAML',\n",
        "    'cv2': 'OpenCV',\n",
        "    'PIL': 'Pillow',\n",
        "}\n",
        "\n",
        "missing = []\n",
        "for pkg, name in required.items():\n",
        "    try:\n",
        "        importlib.import_module(pkg)\n",
        "        print(f\"✓ {name}\")\n",
        "    except ImportError:\n",
        "        print(f\"✗ {name} - NOT INSTALLED\")\n",
        "        missing.append(name)\n",
        "\n",
        "if missing:\n",
        "    print(f\"\\n⚠ Missing: {', '.join(missing)}\")\n",
        "    print(\"Install with: pip install \" + \" \".join(missing))\n",
        "else:\n",
        "    print(\"\\n✓ All dependencies installed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"✓ CUDA available\")\n",
        "    print(f\"  Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"⚠ CUDA not available, will use CPU (slower)\")\n",
        "    device = 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Check InsightFace Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    from insightface.app import FaceAnalysis\n",
        "    \n",
        "    app = FaceAnalysis(name='buffalo_l')\n",
        "    app.prepare(ctx_id=0, det_size=(640, 640))\n",
        "    print(\"✓ InsightFace buffalo_l model loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Failed to load InsightFace model: {e}\")\n",
        "    print(\"  Try: insightface.model_zoo.download('buffalo_l')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Load and Check Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "config_path = os.path.join(project_root, 'config.yaml')\n",
        "\n",
        "if os.path.exists(config_path):\n",
        "    with open(config_path, 'r') as f:\n",
        "        config = yaml.safe_load(f)\n",
        "    print(f\"✓ Config loaded from: {config_path}\")\n",
        "    \n",
        "    # Show key settings\n",
        "    print(\"\\nKey settings:\")\n",
        "    print(f\"  Model: {config.get('model', {}).get('insightface_model', 'N/A')}\")\n",
        "    print(f\"  Dataset path: {config.get('data', {}).get('ms1mv2', {}).get('path', 'N/A')}\")\n",
        "    print(f\"  Latent dim: {config.get('linearizer', {}).get('latent_dim', 'N/A')}\")\n",
        "    print(f\"  Batch size: {config.get('linearizer', {}).get('batch_size', 'N/A')}\")\n",
        "else:\n",
        "    print(f\"✗ Config not found at: {config_path}\")\n",
        "    config = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Check Dataset Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if config:\n",
        "    dataset_path = config.get('data', {}).get('ms1mv2', {}).get('path', '')\n",
        "    \n",
        "    if dataset_path and os.path.exists(dataset_path):\n",
        "        print(f\"✓ Dataset found at: {dataset_path}\")\n",
        "        \n",
        "        # Check structure\n",
        "        images_dir = os.path.join(dataset_path, 'images')\n",
        "        if os.path.exists(images_dir):\n",
        "            print(f\"✓ Images directory found\")\n",
        "            # Try loading a sample\n",
        "            try:\n",
        "                from src.data.dataset import MS1MV2Dataset\n",
        "                dataset = MS1MV2Dataset(dataset_path, is_training=False)\n",
        "                print(f\"✓ Dataset loaded: {len(dataset)} samples\")\n",
        "            except Exception as e:\n",
        "                print(f\"⚠ Could not load dataset: {e}\")\n",
        "        else:\n",
        "            print(f\"⚠ Images directory not found: {images_dir}\")\n",
        "    else:\n",
        "        print(f\"✗ Dataset NOT found at: {dataset_path}\")\n",
        "        print(\"  Please update config.yaml with correct path\")\n",
        "else:\n",
        "    print(\"⚠ Config not loaded, skipping dataset check\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Test Model Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if config:\n",
        "    try:\n",
        "        from utils.model_loader import load_model_from_config\n",
        "        \n",
        "        print(\"Loading model...\")\n",
        "        model = load_model_from_config(config)\n",
        "        model = model.to(device)\n",
        "        model.eval()\n",
        "        \n",
        "        print(\"✓ Model loaded successfully!\")\n",
        "        print(f\"  Embedding size: {getattr(model, 'embedding_size', 'N/A')}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"✗ Failed to load model: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"⚠ Config not loaded, skipping model test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Test Linearizer Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if config and 'model' in locals():\n",
        "    try:\n",
        "        from linearizer.linearizer import Linearizer\n",
        "        \n",
        "        linearizer_config = config['linearizer']\n",
        "        embedding_size = config['model'].get('embedding_size', 512)\n",
        "        \n",
        "        print(\"Creating Linearizer...\")\n",
        "        linearizer = Linearizer(\n",
        "            model=model,\n",
        "            embedding_size=embedding_size,\n",
        "            latent_dim=linearizer_config.get('latent_dim', 512),\n",
        "            num_blocks=linearizer_config.get('num_blocks', 4),\n",
        "            hidden_dim=linearizer_config.get('hidden_dim', 1024),\n",
        "            num_layers=linearizer_config.get('num_layers', 3),\n",
        "            image_size=(112, 112)\n",
        "        )\n",
        "        \n",
        "        print(\"✓ Linearizer created successfully!\")\n",
        "        \n",
        "        # Count parameters\n",
        "        total_params = sum(p.numel() for p in linearizer.parameters())\n",
        "        print(f\"  Total parameters: {total_params:,}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"✗ Failed to create Linearizer: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"⚠ Prerequisites not met, skipping Linearizer test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "If all checks passed, you're ready to run training!\n",
        "\n",
        "**Next steps:**\n",
        "1. Open `notebooks/03_linearization.ipynb` for interactive training\n",
        "2. Or run: `python scripts/train_linearizer.py --config config.yaml`"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
